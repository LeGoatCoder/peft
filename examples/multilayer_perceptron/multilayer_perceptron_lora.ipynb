python -m pip install --upgrade peft


This notebook imports the necessary libraries, including `peft`, `torch`, `nn`, and `F`. It also sets the random seed for reproducibility and ignores the bnb warnings.

## Data

We will create a toy dataset consisting of random data for a classification task. There is a little bit of signal in the data, so we should expect that the loss of the model can improve during training.


This code creates a dataset with random data and labels, splits it into training and evaluation sets, and defines the dataloaders for each set.

## Model

As a model, we use a simple multilayer perceptron (MLP). For demonstration purposes, we use a very large number of hidden units. This is totally overkill for this task but it helps to demonstrate the advantages of `peft`. In more realistic settings, models will also be quite large on average, so this is not far-fetched.


This code defines the MLP model with a single hidden layer and a log softmax output layer.

## Training

Here are just a few training hyper-parameters and a simple function that performs the training and evaluation loop.


This code defines the training function that trains the model for a specified number of epochs and evaluates it on the evaluation set after each epoch.

## Training without peft

Let's start without using `peft` to see what we can expect from the model training.


This code initializes the MLP model, the optimizer, and the loss function.



This code trains the model for 30 epochs and prints the training and evaluation loss after each epoch.

## Training with peft

Now let's train with `peft`. First we check the names of the modules, so that we can configure `peft` to fine-tune the right modules.


This code prints the names and types of all modules in the MLP model.

Next we can define the LoRA config. There is nothing special going on here. We set the LoRA rank to 8 and select the layers `seq.0` and `seq.2` to be used for LoRA fine-tuning. As for `seq.4`, which is the output layer, we set it as `module_
